{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wGNya0M_KhtT"
      },
      "outputs": [],
      "source": [
        "!pip -q install --upgrade openai pandas openpyxl tqdm\n",
        "\n",
        "import os, io, json, time, math\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "from google.colab import files\n",
        "from openai import OpenAI"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "assert os.environ.get(\"OPENAI_API_KEY\"), \"환경변수 OPENAI_API_KEY를 먼저 설정하세요.\"\n",
        "client = OpenAI()"
      ],
      "metadata": {
        "id": "LvDyRG7PTt-8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "uploaded = files.upload()\n",
        "filename = list(uploaded.keys())[0]\n",
        "df = pd.read_excel(io.BytesIO(uploaded[filename]))"
      ],
      "metadata": {
        "id": "-j1wRJO_Txcp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MODEL = \"gpt-4o\"\n",
        "TEMPERATURE = 0\n",
        "N_RUNS = 3\n",
        "MAX_EMOTIONS = 5"
      ],
      "metadata": {
        "id": "TANRd8d-T34j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SYSTEM_INSTRUCTION = (\n",
        "    \"당신은 감성분석 전문가입니다. \"\n",
        "    \"입력 문장에서 느껴지는 감정들을 한국어로 명명하고, 각 감정의 강도를 0~1 사이 확률로 산출하세요. \"\n",
        "    f\"감정 라벨은 자유롭게 정하되, 최대 {MAX_EMOTIONS}개까지만 선택하세요. \"\n",
        "    \"모든 확률의 합은 정확히 1.0이 되도록 하세요. \"\n",
        "    \"반드시 순수 JSON만 출력하고, 형식은 다음과 같습니다: \"\n",
        "    \"{\\\"감정라벨\\\": 확률, ...} (예: {\\\"억울함\\\": 0.4, \\\"분노\\\": 0.3, \\\"불안\\\": 0.3}). \"\n",
        "    \"설명, 코드블록, 불릿 등 JSON 외의 텍스트는 포함하지 마세요.\" )\n",
        "\n",
        "USER_TEMPLATE = \"\"\"다음 문장의 감정 확률 분포를 산출하세요.\n",
        "\n",
        "문장:\n",
        "\\\"\\\"\\\"{text}\\\"\\\"\\\"\n",
        "\n",
        "요구사항 요약:\n",
        "- 감정 라벨: 자유롭게(한국어, 구체적/자연스러운 단어; 예: 억울함, 외로움, 분노, 불안, 수치심, 무력감 등)\n",
        "- 감정 개수 최대 {max_k}개\n",
        "- 확률 합 = 1.0\n",
        "- 출력은 순수 JSON만 (예: {{\"억울함\": 0.4, \"분노\": 0.3, \"불안\": 0.3}})\n",
        "\"\"\"\n",
        "\n",
        "def _normalize_probs(d: dict) -> dict:\n",
        "    if not isinstance(d, dict) or not d:\n",
        "        return {}\n",
        "    clean = {}\n",
        "    for k, v in d.items():\n",
        "        try:\n",
        "            p = float(v)\n",
        "        except:\n",
        "            p = 0.0\n",
        "        if not np.isfinite(p) or p < 0:\n",
        "            p = 0.0\n",
        "        clean[str(k).strip()] = p\n",
        "    s = sum(clean.values())\n",
        "    if s <= 0:\n",
        "        return {}\n",
        "    return {k: (v / s) for k, v in clean.items()}\n",
        "\n",
        "def _topk(d: dict, k: int) -> dict:\n",
        "    if not d:\n",
        "        return {}\n",
        "    items = sorted(d.items(), key=lambda x: x[1], reverse=True)[:k]\n",
        "    return _normalize_probs(dict(items))\n",
        "\n",
        "def _call_once(text: str, max_retries: int = 3, backoff: float = 1.5) -> dict:\n",
        "    prompt = USER_TEMPLATE.format(text=text, max_k=MAX_EMOTIONS)\n",
        "    for attempt in range(max_retries):\n",
        "        try:\n",
        "            resp = client.responses.create(\n",
        "                model=MODEL,\n",
        "                temperature=TEMPERATURE,\n",
        "                instructions=SYSTEM_INSTRUCTION,\n",
        "                input=prompt,\n",
        "            )\n",
        "            raw = resp.output_text.strip()\n",
        "            data = json.loads(raw)\n",
        "            if not isinstance(data, dict):\n",
        "                raise ValueError(\"JSON 객체가 아님\")\n",
        "            data = _normalize_probs(data)\n",
        "            data = _topk(data, MAX_EMOTIONS)\n",
        "            return data\n",
        "        except Exception as e:\n",
        "            if attempt == max_retries - 1:\n",
        "                print(f\"⚠️ 분석 실패(최종): {e}\")\n",
        "                return {}\n",
        "            time.sleep(backoff ** attempt)\n",
        "\n",
        "def analyze_emotion_distribution_3run(text: str) -> dict:\n",
        "    if not isinstance(text, str) or not text.strip():\n",
        "        return {}\n",
        "    agg = {}\n",
        "    for _ in range(N_RUNS):\n",
        "        d = _call_once(text)\n",
        "        for k, v in d.items():\n",
        "            agg[k] = agg.get(k, 0.0) + v\n",
        "    if not agg:\n",
        "        return {}\n",
        "    for k in list(agg.keys()):\n",
        "        agg[k] /= N_RUNS\n",
        "    return _normalize_probs(agg)\n",
        "\n",
        "def extract_top_emotions(em_dict, top_n=3):\n",
        "    if not isinstance(em_dict, dict) or not em_dict:\n",
        "        return [None] * top_n\n",
        "    items = sorted(em_dict.items(), key=lambda x: x[1], reverse=True)[:top_n]\n",
        "    names = [k for k, _ in items]\n",
        "    return names + [None] * (top_n - len(names))"
      ],
      "metadata": {
        "id": "aKaGKj0LT9y3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if \"원자료\" not in df.columns:\n",
        "    raise ValueError(\"엑셀에 '원자료' 컬럼이 필요합니다.\")\n",
        "\n",
        "texts = df[\"원자료\"].astype(str).fillna(\"\").tolist()\n",
        "\n",
        "out = []\n",
        "for t in tqdm(texts, desc=\"감정 분석 중\"):\n",
        "    out.append(analyze_emotion_distribution_3run(t))\n",
        "\n",
        "df[\"감정확률분포\"] = out\n",
        "tops = df[\"감정확률분포\"].apply(lambda d: pd.Series(extract_top_emotions(d, top_n=3), index=[\"감정1\",\"감정2\",\"감정3\"]))\n",
        "df = pd.concat([df, tops], axis=1)\n",
        "\n",
        "output_file = \"/content/gpt_감정확률분석_결과.xlsx\"\n",
        "df.to_excel(output_file, index=False)\n",
        "files.download(output_file)\n",
        "\n",
        "print(\"완료 ✅ →\", output_file)"
      ],
      "metadata": {
        "id": "Tm2ZeSqRUA4L"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}